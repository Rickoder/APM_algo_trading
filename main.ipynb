{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should implement and back-test trading algorithms using historical market data.\n",
    "\n",
    "The project is divided into three main strategies:\n",
    "\n",
    "1. Moving Average and Momentum Strategies,\n",
    "2. Value-Based Strategies, and\n",
    "3. Sentiment-Based Strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write our own Back Testing Code\n",
    "\n",
    "▪ Back Testing simulates how a trading strategy would have performed in the past using historical data.\n",
    "▪ The purpose is to evaluate the strategy's effectiveness, identify potential issues, and refine it before deploying it in live trading.\n",
    "▪ Here are key components a back-testing code needs to handle:\n",
    "    1. Load up and process price and other data\n",
    "    2. Clean and prepare data\n",
    "    3. Implement logic to buy and sell based on signals\n",
    "    4. Define trades and measure their performance over time\n",
    "    5. Incorporate realistic transaction costs\n",
    "    6. Calculate metrics – return, drawdown, Sharpe ratio etc.…\n",
    "    7. Visualise results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and Sanity Checks\n",
    "\n",
    "▪ Out-of-Sample Testing:\n",
    "    ▪ After optimizing the strategy on historical data, test it on a separate dataset (out-of-sample data) to verify its robustness.\n",
    "▪ Sanity Checks:\n",
    "    ▪ Ensure the backtest is realistic (e.g., no future data leakage, no unrealistic execution assumptions) to prevent overestimating the strategy’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13356 entries, 0 to 13355\n",
      "Columns: 410 entries, Date to ZTS_adjclose\n",
      "dtypes: float64(409), object(1)\n",
      "memory usage: 41.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ludov\\AppData\\Local\\Temp\\ipykernel_9156\\547824506.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13356 entries, 0 to 13355\n",
      "Columns: 253 entries, Date to ZION_adjclose\n",
      "dtypes: datetime64[ns](1), float64(252)\n",
      "memory usage: 25.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DF_fully_cleaned_stock_data.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the stock data\n",
    "file_path = \"DF_stock_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information and the first few rows\n",
    "df.info(), df.head()\n",
    "\n",
    "# Convert Date column to datetime format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Sort data by Date\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Forward-fill missing values to maintain continuity\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Drop columns where more than 50% of data is missing\n",
    "threshold = len(df) * 0.5\n",
    "df = df.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "# Remove any duplicate rows if present\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Display cleaned dataset info\n",
    "df.info(), df.head()\n",
    "\n",
    "# Define the new file path\n",
    "cleaned_file_path = \"DF_cleaned_stock_data.csv\"\n",
    "\n",
    "# Save the cleaned dataset to CSV\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Return the file path for download\n",
    "cleaned_file_path\n",
    "\n",
    "# Drop rows where any column has missing values to keep only complete data\n",
    "df_complete = df.dropna()\n",
    "\n",
    "# Save the fully cleaned dataset\n",
    "complete_file_path = \"DF_fully_cleaned_stock_data.csv\"\n",
    "df_complete.to_csv(complete_file_path, index=False)\n",
    "\n",
    "# Return the file path for download\n",
    "complete_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 1: Moving Average and Momentum Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules based Moving average startegy\n",
    "\n",
    "Understand & implement moving average strategies\n",
    "    ▪ Simple Moving Average (SMA)\n",
    "    ▪ Write code that calculates this to different periods\n",
    "\n",
    "Tasks:\n",
    "    1. Implement a strategy where a short-term moving average (e.g., S-day SMA) crosses above or below a long-term moving average (e.g., L-day SMA).\n",
    "    2. Write code to execute buy orders when the short-term average crosses above the long-term average and sell orders when the opposite occurs.\n",
    "    3. Test the algorithm on a broad range of stocks (at least 100) from the S&P index for a range of values of S and L\n",
    "    4. You should report average P&L and variance of P&L for each combination of moving average periods"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 233\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m<\u001b[39m l:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (rsi_buy, rsi_sell) \u001b[38;5;129;01min\u001b[39;00m rsi_thresholds:\n\u001b[1;32m--> 233\u001b[0m         trades_list \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[0;32m    234\u001b[0m             delayed(get_trades_for_ticker_combined)(df, s, l, rsi_buy, rsi_sell) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m stock_dfs\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    235\u001b[0m         )\n\u001b[0;32m    236\u001b[0m         all_trades \u001b[38;5;241m=\u001b[39m [trade \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m trades_list \u001b[38;5;28;01mfor\u001b[39;00m trade \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m all_trades:\n",
      "File \u001b[1;32mc:\\Users\\ludov\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\ludov\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ludov\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving Average Crossover Strategy Results:\n",
      "    Short_MA  Long_MA  Average_PnL  Variance_PnL\n",
      "0          5       50     7.871429  6.958341e+05\n",
      "1          5       70     7.423369  7.307737e+05\n",
      "2          5      100    15.178919  1.514370e+06\n",
      "3          5      150    15.532509  1.714463e+06\n",
      "4          5      200    20.153850  2.455918e+06\n",
      "5          7       50     7.427176  7.856267e+05\n",
      "6          7       70    10.152610  8.656064e+05\n",
      "7          7      100    19.006505  1.689013e+06\n",
      "8          7      150    21.636478  1.819870e+06\n",
      "9          7      200    21.248463  2.320816e+06\n",
      "10        10       50     9.248550  8.046415e+05\n",
      "11        10       70    12.754032  1.051194e+06\n",
      "12        10      100    20.331770  1.913846e+06\n",
      "13        10      150    26.027039  2.050271e+06\n",
      "14        10      200    24.428110  2.798834e+06\n",
      "15        15       50     8.970257  8.972154e+05\n",
      "16        15       70    10.264637  1.046650e+06\n",
      "17        15      100    25.071525  2.236426e+06\n",
      "18        15      150    30.034991  2.174554e+06\n",
      "19        15      200    34.442247  3.213274e+06\n",
      "20        20       50    11.137836  8.476352e+05\n",
      "21        20       70    12.536386  1.330939e+06\n",
      "22        20      100    33.414928  2.524331e+06\n",
      "23        20      150    31.821122  4.346768e+06\n",
      "24        20      200    36.196076  3.752870e+06\n",
      "\n",
      "RSI Strategy Results:\n",
      "   RSI_Buy  RSI_Sell  Average_PnL  Variance_PnL\n",
      "0       70        30     9.118710  9.605363e+05\n",
      "1       75        25     6.264343  1.284636e+06\n",
      "2       65        35     7.821172  6.608964e+05\n",
      "3       80        20    25.029141  4.460911e+06\n",
      "4       60        40     6.830699  4.209718e+05\n",
      "\n",
      "Combined MA & RSI Strategy Results:\n",
      "     Short_MA  Long_MA  RSI_Buy  RSI_Sell  Average_PnL  Variance_PnL\n",
      "0           5       50       70        30    87.323680  5.177855e+06\n",
      "1           5       50       75        25   141.333313  1.419240e+07\n",
      "2           5       50       65        35    29.296883  2.781809e+06\n",
      "3           5       50       80        20   468.540770  5.321128e+07\n",
      "4           5       50       60        40    18.794306  2.499787e+06\n",
      "..        ...      ...      ...       ...          ...           ...\n",
      "120        20      200       70        30   173.087440  1.868244e+07\n",
      "121        20      200       75        25   198.933560  2.239913e+07\n",
      "122        20      200       65        35   109.966246  9.115586e+06\n",
      "123        20      200       80        20   402.374111  4.051579e+07\n",
      "124        20      200       60        40    72.203448  6.925892e+06\n",
      "\n",
      "[125 rows x 6 columns]\n"
>>>>>>> Nithun/master
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions to Compute Indicators\n",
    "# -------------------------------\n",
    "\n",
    "def compute_indicators_for_stock(df, ma_periods, rsi_period=14):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with columns 'Date' and 'Price', compute moving averages for each period in ma_periods\n",
    "    and compute the RSI using the specified rsi_period.\n",
    "    \"\"\"\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Compute moving averages\n",
    "    for period in ma_periods:\n",
    "        df[f\"MA {period}\"] = df['Price'].rolling(window=period).mean()\n",
    "    \n",
    "    # Compute RSI (using the standard 14-day period by default)\n",
    "    delta = df['Price'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window=rsi_period).mean()\n",
    "    avg_loss = loss.rolling(window=rsi_period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Simulation Functions for Strategies\n",
    "# -------------------------------\n",
    "\n",
    "def simulate_ma_strategy(df, short_window, long_window):\n",
    "    \"\"\"\n",
    "    Simulate a moving average crossover strategy:\n",
    "      - Buy when the short MA crosses above the long MA.\n",
    "      - Sell when the short MA crosses below the long MA.\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    in_position = False\n",
    "    entry_price = 0.0\n",
    "\n",
    "    ma_short = df[f\"MA {short_window}\"]\n",
    "    ma_long  = df[f\"MA {long_window}\"]\n",
    "    price    = df['Price']\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # Buy signal: short MA crosses above long MA\n",
    "        if not in_position and (ma_short.iloc[i] > ma_long.iloc[i]) and (ma_short.iloc[i-1] <= ma_long.iloc[i-1]):\n",
    "            in_position = True\n",
    "            entry_price = price.iloc[i]\n",
    "        # Sell signal: short MA crosses below long MA\n",
    "        elif in_position and (ma_short.iloc[i] < ma_long.iloc[i]) and (ma_short.iloc[i-1] >= ma_long.iloc[i-1]):\n",
    "            exit_price = price.iloc[i]\n",
    "            trades.append(exit_price - entry_price)\n",
    "            in_position = False\n",
    "\n",
    "    # Close any open position at the end of the series\n",
    "    if in_position:\n",
    "        trades.append(price.iloc[-1] - entry_price)\n",
    "        \n",
    "    return trades\n",
    "\n",
    "def simulate_rsi_strategy(df, rsi_buy_threshold, rsi_sell_threshold):\n",
    "    \"\"\"\n",
    "    Simulate an RSI-based strategy:\n",
    "      - Buy when RSI exceeds the buy threshold.\n",
    "      - Sell when RSI falls below the sell threshold.\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    in_position = False\n",
    "    entry_price = 0.0\n",
    "    price = df['Price']\n",
    "    rsi   = df['RSI']\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if not in_position and (rsi.iloc[i] > rsi_buy_threshold):\n",
    "            in_position = True\n",
    "            entry_price = price.iloc[i]\n",
    "        elif in_position and (rsi.iloc[i] < rsi_sell_threshold):\n",
    "            exit_price = price.iloc[i]\n",
    "            trades.append(exit_price - entry_price)\n",
    "            in_position = False\n",
    "\n",
    "    if in_position:\n",
    "        trades.append(price.iloc[-1] - entry_price)\n",
    "    return trades\n",
    "\n",
    "def simulate_combined_strategy(df, short_window, long_window, rsi_buy_threshold, rsi_sell_threshold):\n",
    "    \"\"\"\n",
    "    Simulate a combined strategy:\n",
    "      - Buy when a short MA crosses above a long MA and RSI exceeds the buy threshold.\n",
    "      - Sell when a short MA crosses below a long MA and RSI falls below the sell threshold.\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    in_position = False\n",
    "    entry_price = 0.0\n",
    "    price = df['Price']\n",
    "    ma_short = df[f\"MA {short_window}\"]\n",
    "    ma_long  = df[f\"MA {long_window}\"]\n",
    "    rsi      = df['RSI']\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if not in_position and (ma_short.iloc[i] > ma_long.iloc[i]) and (ma_short.iloc[i-1] <= ma_long.iloc[i-1]) and (rsi.iloc[i] > rsi_buy_threshold):\n",
    "            in_position = True\n",
    "            entry_price = price.iloc[i]\n",
    "        elif in_position and (ma_short.iloc[i] < ma_long.iloc[i]) and (ma_short.iloc[i-1] >= ma_long.iloc[i-1]) and (rsi.iloc[i] < rsi_sell_threshold):\n",
    "            exit_price = price.iloc[i]\n",
    "            trades.append(exit_price - entry_price)\n",
    "            in_position = False\n",
    "\n",
    "    if in_position:\n",
    "        trades.append(price.iloc[-1] - entry_price)\n",
    "    return trades\n",
    "\n",
    "# -------------------------------\n",
    "# Wrapper Functions for Parallel Processing\n",
    "# -------------------------------\n",
    "\n",
    "def get_trades_for_ticker_ma(df, s, l):\n",
    "    if f\"MA {s}\" in df.columns and f\"MA {l}\" in df.columns:\n",
    "        return simulate_ma_strategy(df, s, l)\n",
    "    return []\n",
    "\n",
    "def get_trades_for_ticker_rsi(df, rsi_buy, rsi_sell):\n",
    "    if 'RSI' in df.columns:\n",
    "        return simulate_rsi_strategy(df, rsi_buy, rsi_sell)\n",
    "    return []\n",
    "\n",
    "def get_trades_for_ticker_combined(df, s, l, rsi_buy, rsi_sell):\n",
    "    if (f\"MA {s}\" in df.columns) and (f\"MA {l}\" in df.columns) and ('RSI' in df.columns):\n",
    "        return simulate_combined_strategy(df, s, l, rsi_buy, rsi_sell)\n",
    "    return []\n",
    "\n",
    "# -------------------------------\n",
    "# Main Backtesting Process\n",
    "# -------------------------------\n",
    "\n",
    "# Load the CSV file.\n",
    "# The CSV is assumed to have the first column as \"Date\" and all subsequent columns are adjusted close prices for S&P 500 stocks.\n",
    "data = pd.read_csv('DF_fully_cleaned_stock_data.csv', parse_dates=['Date'])\n",
    "data.sort_values('Date', inplace=True)\n",
    "\n",
    "# All columns except 'Date' represent different stocks.\n",
    "tickers = data.columns[1:]\n",
    "\n",
    "# Define the moving average periods of interest.\n",
    "short_windows = [5, 7, 10, 15, 20]\n",
    "long_windows  = [50, 70, 100, 150, 200]\n",
    "ma_periods = sorted(list(set(short_windows + long_windows)))\n",
    "\n",
    "# Build a dictionary with processed DataFrames for each ticker.\n",
    "stock_dfs = {}\n",
    "for ticker in tickers:\n",
    "    df_stock = data[['Date', ticker]].rename(columns={ticker: 'Price'})\n",
    "    df_stock = compute_indicators_for_stock(df_stock, ma_periods, rsi_period=14)\n",
    "    stock_dfs[ticker] = df_stock\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Evaluate the MA Crossover Strategy using Parallel Processing\n",
    "# -------------------------------\n",
    "ma_results = []\n",
    "for s in short_windows:\n",
    "    for l in long_windows:\n",
    "        if s < l:\n",
    "            trades_list = Parallel(n_jobs=-1)(\n",
    "                delayed(get_trades_for_ticker_ma)(df, s, l) for df in stock_dfs.values()\n",
    "            )\n",
    "            # Flatten the list of trade results\n",
    "            all_trades = [trade for sublist in trades_list for trade in sublist]\n",
    "            if all_trades:\n",
    "                avg_pnl = np.mean(all_trades)\n",
    "                var_pnl = np.var(all_trades)\n",
    "            else:\n",
    "                avg_pnl = np.nan\n",
    "                var_pnl = np.nan\n",
    "            ma_results.append({\n",
    "                'Short_MA': s,\n",
    "                'Long_MA': l,\n",
    "                'Average_PnL': avg_pnl,\n",
    "                'Variance_PnL': var_pnl\n",
    "            })\n",
    "\n",
    "ma_results_df = pd.DataFrame(ma_results)\n",
    "print(\"Moving Average Crossover Strategy Results:\")\n",
    "print(ma_results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Evaluate the RSI-only Strategy using Parallel Processing\n",
    "# -------------------------------\n",
    "# Define a list of RSI threshold pairs to test: (RSI_buy_threshold, RSI_sell_threshold)\n",
    "rsi_thresholds = [\n",
    "    (70, 30),\n",
    "    (75, 25),\n",
    "    (65, 35),\n",
    "    (80, 20),\n",
    "    (60, 40)\n",
    "]\n",
    "\n",
    "rsi_results = []\n",
    "for (rsi_buy, rsi_sell) in rsi_thresholds:\n",
    "    trades_list = Parallel(n_jobs=-1)(\n",
    "        delayed(get_trades_for_ticker_rsi)(df, rsi_buy, rsi_sell) for df in stock_dfs.values()\n",
    "    )\n",
    "    all_trades = [trade for sublist in trades_list for trade in sublist]\n",
    "    if all_trades:\n",
    "        avg_pnl = np.mean(all_trades)\n",
    "        var_pnl = np.var(all_trades)\n",
    "    else:\n",
    "        avg_pnl = np.nan\n",
    "        var_pnl = np.nan\n",
    "    rsi_results.append({\n",
    "        'RSI_Buy': rsi_buy,\n",
    "        'RSI_Sell': rsi_sell,\n",
    "        'Average_PnL': avg_pnl,\n",
    "        'Variance_PnL': var_pnl\n",
    "    })\n",
    "\n",
    "# rsi_results_df = pd.DataFrame(rsi_results)\n",
    "# print(\"\\nRSI Strategy Results:\")\n",
    "# print(rsi_results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Evaluate the Combined MA & RSI Strategy using Parallel Processing\n",
    "# -------------------------------\n",
    "combined_results = []\n",
    "for s in short_windows:\n",
    "    for l in long_windows:\n",
    "        if s < l:\n",
    "            for (rsi_buy, rsi_sell) in rsi_thresholds:\n",
    "                trades_list = Parallel(n_jobs=-1)(\n",
    "                    delayed(get_trades_for_ticker_combined)(df, s, l, rsi_buy, rsi_sell) for df in stock_dfs.values()\n",
    "                )\n",
    "                all_trades = [trade for sublist in trades_list for trade in sublist]\n",
    "                if all_trades:\n",
    "                    avg_pnl = np.mean(all_trades)\n",
    "                    var_pnl = np.var(all_trades)\n",
    "                else:\n",
    "                    avg_pnl = np.nan\n",
    "                    var_pnl = np.nan\n",
    "                combined_results.append({\n",
    "                    'Short_MA': s,\n",
    "                    'Long_MA': l,\n",
    "                    'RSI_Buy': rsi_buy,\n",
    "                    'RSI_Sell': rsi_sell,\n",
    "                    'Average_PnL': avg_pnl,\n",
    "                    'Variance_PnL': var_pnl\n",
    "                })\n",
    "\n",
    "combined_results_df = pd.DataFrame(combined_results)\n",
    "print(\"\\nCombined MA & RSI Strategy Results:\")\n",
    "print(combined_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules based Momentum startegy\n",
    "\n",
    "Understand the concept of momentum\n",
    "    ▪ Relative Strength Index (RSI)\n",
    "    ▪ Write code to calculate these\n",
    "\n",
    "Tasks:\n",
    "    1. Implement a strategy that buys assets when momentum indicators signal strength (e.g., RSI > 70) and sells when they signal weakness (e.g., RSI < 30).\n",
    "    2. Combine momentum signals with moving averages to enhance the strategy.\n",
    "    3. Test the algorithm on a broad range of stocks (at least 100) from the S&P index\n",
    "    4. You should report average P&L and variance of P&L for each combination of moving average periods\n",
    "    5. Once again try five best combinations of RSI you can find both alone and combined with moving averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML based Moving average strategy\n",
    "\n",
    "Tasks:\n",
    "    1. Build a Deep Learning model that takes in the stock prices and ML indicators and RSI indicators as features\n",
    "    2. Use a 3-layer neural network (1 hidden layers) where the inputs are the indicators and the output is a buy, sell or hold signal\n",
    "    3. You train it over a subset of the time series\n",
    "    4. You test it on another part of the timeseries\n",
    "    5. See if the changing number of layers or neurons per layer helps\n",
    "    6. Test the algorithm on a broad range of stocks (at least 100) from the S&P index\n",
    "    7. You should report average P&L and variance of P&L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML based Momentum strategy\n",
    "\n",
    "Tasks:\n",
    "    1. Implement a strategy that buys assets when momentum indicators signal strength (e.g., RSI > 70) and sells when they signal weakness (e.g., RSI < 30).\n",
    "    2. Combine momentum signals with moving averages to enhance the strategy.\n",
    "    3. Once again try five best combinations of RSI you can find both alone and combined with moving averages\n",
    "    4. Use a machine learning algorithm with price, and various MA values and RSI as features to see if you can predict buy and sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 2: Value-Based Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives:\n",
    "• Understand fundamental metrics such as P/E ratios, book value\n",
    "• Backtest value-based strategies using historical data.\n",
    "• Evaluate the performance of the strategies.\n",
    "\n",
    "Tasks:\n",
    "    1. Buy stocks with low P/E ratio compared to historical average\n",
    "    2. The Price-to-Book ratio compares a company's market value to its book value (the net asset value on the balance sheet). A low P/B ratio may indicate that the stock is undervalued relative to its assets.\n",
    "    3. Use a machine learning algorithm with price, P/E and PtB values as features to see if you can predict buy and sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 3: Sentiment-Based Strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▪ Understand and implement sentiment-based trading strategies.\n",
    "▪ Analyze sentiment data from news articles, social media, and other sources.\n",
    "▪ Backtest sentiment-based strategies using historical sentiment data.\n",
    "▪ Evaluate the performance of sentiment-based strategies.\n",
    "\n",
    "Implement a Sentiment-Based Trading Strategy:\n",
    "    ▪ Develop a strategy that buys stocks with positive sentiment and sells stocks with negative sentiment.\n",
    "    ▪ Experiment with different thresholds for sentiment scores to refine the strategy.\n",
    "    ▪ Combine sentiment analysis with the moving average and value-based strategies from previous sections.\n",
    "    ▪ Explore how sentiment signals can enhance or detract from other strategies.\n",
    "    ▪ Use historical sentiment data alongside market data to backtest the sentiment-based strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "price_df = pd.read_csv(\"DF_fully_cleaned_stock_data.csv\")\n",
    "pe_df = pd.read_csv(\"PE RATIO.csv\")\n",
    "ptb_df = pd.read_csv(\"price_to_book_ratio.csv\")\n",
    "\n",
    "# Parse date columns\n",
    "price_df['Date'] = pd.to_datetime(price_df['Date'])\n",
    "pe_df['Dates'] = pd.to_datetime(pe_df['Dates'], format='%d-%m-%Y')\n",
    "ptb_df['Date'] = pd.to_datetime(ptb_df['Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Melt the data to long format\n",
    "price_melted = price_df.melt(id_vars='Date', var_name='Stock', value_name='Close')\n",
    "pe_melted = pe_df.melt(id_vars='Dates', var_name='Stock', value_name='PE').rename(columns={'Dates': 'Date'})\n",
    "ptb_melted = ptb_df.melt(id_vars='Date', var_name='Stock', value_name='PB')\n",
    "\n",
    "# Clean ticker names\n",
    "clean = lambda x: x.replace('_adjclose', '').replace(' UW Equity', '').replace(' UN Equity', '').strip()\n",
    "price_melted['Stock'] = price_melted['Stock'].apply(clean)\n",
    "pe_melted['Stock'] = pe_melted['Stock'].apply(clean)\n",
    "ptb_melted['Stock'] = ptb_melted['Stock'].apply(clean)\n",
    "\n",
    "# Merge datasets\n",
    "merged_df = price_melted.merge(pe_melted, on=['Date', 'Stock'], how='inner')\n",
    "merged_df = merged_df.merge(ptb_melted, on=['Date', 'Stock'], how='inner')\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "# Export\n",
    "merged_df.to_csv(\"cleaned_stock_pe_pb_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
